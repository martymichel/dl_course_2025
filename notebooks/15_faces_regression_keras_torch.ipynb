{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJE2B4XUDNWu"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorchiefs/dlwbl_eth25/blob/master/notebooks/03_uk_faces.ipynb)\n",
    "\n",
    "# Probabilistic Age Regression based on images\n",
    "\n",
    "In this notebook you will use images of faces to set up regression models that outputs a  conditional gaussian probability distribution $p(y|x)$ for the age of the displayed person.\n",
    "\n",
    "**Dataset:**\n",
    "You work with a the [UTKFace dataset](https://susanqq.github.io/UTKFace/).  The dataset consists of over 20,000 face images with annotations of age, gender (and ethnicity). The data is already preprocessed and rescaled (80x80 pixels).\n",
    "\n",
    "\n",
    "**GPU:**\n",
    "It is better to use the GPU for this notebook. If you are using colab, you can change the runtime type in the menu: Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n",
    "\n",
    "**Your Task**\n",
    "Steps through the notebook, try to understand the code and fill out the cells with (üîß YOUR TASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwPE59up64GY"
   },
   "source": [
    "#### Settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-zUHKT6MLIS"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15   #Change this to smaller number for testing, negative means load the weights from dropbox (only for JAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KnXMRS7zgrB",
    "outputId": "0f8a220f-9e08-4d02-879b-bfea201100f8"
   },
   "outputs": [],
   "source": [
    "### Running on Colab\n",
    "import sys\n",
    "import time\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "print(f\"Running on Colab: {IN_COLAB} date {time.asctime()} UTC\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmKqNv7dKAvg"
   },
   "source": [
    "##### Imports and setting the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7pHgvcrMLIT",
    "outputId": "423ebee1-a587-4595-a31e-335178e7d7db"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline is fine for Jupyter environments\n",
    "%matplotlib inline\n",
    "\n",
    "# General-purpose libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Keras + Backend setup (must be before importing keras)\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (\n",
    "    Dense, Convolution2D, MaxPooling2D, Flatten,\n",
    "    Activation, Dropout, Input, Concatenate\n",
    ")\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import to_categorical\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Image handling\n",
    "from PIL import Image\n",
    "\n",
    "# Environment & backend checks\n",
    "print(f'Keras_version: {keras.__version__}')  # e.g. 3.5.0\n",
    "print(f'Torch_version: {torch.__version__}')  # e.g. 2.5.1+cu121\n",
    "print(f'Keras backend: {K.backend()}')\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "cuda_version = torch.version.cuda if cuda_available else \"N/A\"\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "print(f\"CUDA Version: {cuda_version}\")\n",
    "\n",
    "# Device selection\n",
    "if cuda_available:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"‚úÖ CUDA is available. Using GPU.\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"‚úÖ MPS (Apple Silicon GPU) is available. Using MPS.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"‚ùå No GPU available. Using CPU.\")\n",
    "\n",
    "print(f\"Device selected: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdnkSVWmJUXX"
   },
   "source": [
    "#### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxbUKL78JVKy",
    "outputId": "ef677caa-9b5b-49a0-91da-ea3190066a96"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('X_faces.npy'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/5m7nmebpjysqtus/X_faces.npy?dl=1\",\n",
    "    \"X_faces.npy\")\n",
    "!ls -lh X_face*\n",
    "\n",
    "if not os.path.isfile('Y_age.npy'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/flpyvgdqoatdw0g/Y_age.npy?dl=1\",\n",
    "    \"Y_age.npy\")\n",
    "!ls -lh Y*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_B_EJ00sKIiN",
    "outputId": "d7684180-c536-408f-9ed2-42080d570c2f"
   },
   "outputs": [],
   "source": [
    "X=np.load(\"X_faces.npy\")\n",
    "Y=np.load(\"Y_age.npy\")\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4PHsH3dJdT6"
   },
   "source": [
    "#### Splitting the data into train, val and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mk4yqoyEZ80S",
    "outputId": "e73e6a5b-2660-4bb4-f63d-27b5d045dc62"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=201)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=34)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOc3Er5yNCUH"
   },
   "source": [
    "#### Looking at a few image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "T5pSRxfiNBT_",
    "outputId": "d7a663c2-3bc3-4713-b9a9-0955c9c9ac17"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "for i in range(0,9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(\"Age : \"+ str(y_train[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wET5EAj1KGUk"
   },
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LtYwRKyaWUR"
   },
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_val=X_val/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwwWDz3ILy2V"
   },
   "source": [
    "#### Looking at the age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "SHJvwt2aKNeC",
    "outputId": "50611775-12fb-49a9-efbb-66254b13a9f5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(y_train, bins=30, kde=True, color='blue', line_kws={'linewidth': 5.5})\n",
    "plt.title(\"Age Distribution in Training Set\", fontsize=15)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(y_val, bins=30, kde=True, color='green')\n",
    "plt.title(\"Age Distribution in Validation Set\", fontsize=15)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyB4RlYFqJAS"
   },
   "source": [
    "#### üîß **Exercise 1:** implement Null Model\n",
    "\n",
    "Use a null model, which simply predicts a Gaussian describing the marginal age distribution (independent of an individual image).\n",
    "\n",
    "##### i) Estimation of $\\mu$ and $\\sigma$\n",
    "\n",
    "You should get $\\hat{\\mu} \\approx 33.14$ and $\\hat{\\sigma} \\approx 19.81$.\n",
    "\n",
    "##### ii) Calculate the NLL of the null model on the testset\n",
    "\n",
    "You should get a NLL of $\\approx 4.4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBdt7-P5e9bC"
   },
   "source": [
    "Recall the density function of the normal distribution:\n",
    "$$\n",
    "p(y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0crL7psqEey",
    "outputId": "eff054af-d359-464c-95b2-d398a819b1c9"
   },
   "outputs": [],
   "source": [
    "# @title üîë Solution Code { display-mode: \"form\" }\n",
    "#### üéØ Solution ########\n",
    "\n",
    "# i) NLL\n",
    "mu_naive = np.mean(y_train)\n",
    "sd_naive = np.std(y_train)\n",
    "\n",
    "print(f\"mu_naive: {mu_naive}\")\n",
    "print(f\"sd_naive: {sd_naive}\")\n",
    "\n",
    "# ii) Calculate NLL on testset\n",
    "nll_naive = 0\n",
    "for i in range(len(X_test)):  # Iterate over the entire test set\n",
    "    # Calculate the log probability using NumPy\n",
    "    log_prob = -0.5 * np.log(2 * np.pi * sd_naive**2) - (y_test[i] - mu_naive)**2 / (2 * sd_naive**2)\n",
    "    nll_naive -= log_prob  # Accumulate negative log probability\n",
    "\n",
    "nll_naive /= len(X_test)  # Average the NLL over the test set\n",
    "\n",
    "print(f\"NLL for naive prediction (NumPy): {nll_naive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cGc0WOZ4sqV"
   },
   "source": [
    "#### Prepare Data\n",
    "\n",
    "\n",
    "Note that the reshape in the following cell is extremly important. This makes the shape of y from $(B,)$ to $(B,1)$ - a shape of $(B,)$ would cause strange broadcast errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NoY1l3TA82d",
    "outputId": "eef8365d-39dc-42ac-ac07-15415e4f5427"
   },
   "outputs": [],
   "source": [
    "print(X_train.mean())  # check if centered around approx 0.5\n",
    "print(X_val.mean())\n",
    "print(X_val.mean())\n",
    "print(\"Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2_-fUp88Zxn",
    "outputId": "868d7aff-e842-4a92-f06f-c917e17ef328"
   },
   "outputs": [],
   "source": [
    "##### NOTE THE RESHAPE IS EXTREMLY IMPORTANT ####\n",
    "y_train = y_train.reshape(-1,1) # this reshape is important!\n",
    "y_val = y_val.reshape(-1,1)     # it adds a new dimension\n",
    "y_test = y_test.reshape(-1,1)   # after the last dim (-1)\n",
    "print(y_train.shape) #Need to have the last dimension of ,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DB2ecXi2UQY"
   },
   "source": [
    "### Output of NN to Gaussian Distribution\n",
    "\n",
    "The output NN has the form (B, 2) with the first dimension. The last two dimensions code the mean and the log(sd) of the Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQEkkEsdZQvu"
   },
   "outputs": [],
   "source": [
    "# Wrapper function to convert model output to a PyTorch Normal distribution\n",
    "import torch\n",
    "from torch.distributions import Normal\n",
    "\n",
    "@staticmethod\n",
    "def output_to_gaussian_distribution(output):\n",
    "    mean = output[:, 0:1]\n",
    "    log_sd = output[:, 1:2]\n",
    "    scale = torch.exp(log_sd)  # Ensure positive scale\n",
    "    return torch.distributions.Normal(loc=mean, scale=scale)\n",
    "\n",
    "def NLL(y_true, output):\n",
    "  dist = output_to_gaussian_distribution(output)\n",
    "  return -dist.log_prob(y_true).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzkJVe4oOkIh"
   },
   "source": [
    "## Fit a regression model with flexible variance\n",
    "In the next cells you will again define and fit a model on the face images. You will use a CNN to model the mu parameter of a gaussian conditional probability distribution, but this time the sigma will not be constant for all inputs. Every iamge will be able to have a different sigma. For the loss we use the NLL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8vYpToHZ-7i"
   },
   "outputs": [],
   "source": [
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)\n",
    "input1 = Input(shape=(80,80,3))\n",
    "x = Convolution2D(16,kernel_size,padding='same',activation=\"relu\")(input1)\n",
    "x = Convolution2D(16,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "x = Flatten(name = 'bef_split')(x)\n",
    "\n",
    "# One HEAD\n",
    "x = Dense(2*500, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(2*50, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "mean_and_sd_layer = Dense(2)(x)\n",
    "\n",
    "model_flex = Model(inputs=input1, outputs=mean_and_sd_layer)\n",
    "\n",
    "from keras import ops as K  # Use keras.ops instead of keras.backend\n",
    "\n",
    "# Custom MAE metric\n",
    "def custom_mae(y_true, y_pred):\n",
    "    mean_pred = y_pred[:, 0]  # Extract mean predictions\n",
    "    return K.mean(K.abs(y_true - mean_pred))  # Use ops for math operations\n",
    "\n",
    "model_flex.compile(optimizer=\"adam\", loss=NLL, metrics=[custom_mae, 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504,
     "referenced_widgets": [
      "4f3d63553cc94978be0e125354844f54",
      "b703f757504a4d0b89490b7caf97d179",
      "76cfff96f9c04effb3fd5c50cfeafc36",
      "82f5cf6b7313431b9239e6c2e2cf7289",
      "e48808cdedb84723a9dd3f16b513c8d5",
      "73e930992aea476989c4f8909e0d28b1",
      "730945c09f1c4d6e93d103357443db57",
      "84e9dc41cb7844f9a93fa8fa0059358e",
      "9c38bf7b2f214fa1b99e636897f70718",
      "e14e97bba6a1457e8e16c937df124a61",
      "a07b4fb8b63445b6a4e9ad0c90b31df6",
      "d962380c30e94d8489953d579e4c4863",
      "6d2817611553445fba2827a36cd73b9f",
      "232ba79528ec49e69dbdce54121ee6ee",
      "d73bd0de03d0407f84b15cf32fff61a6",
      "471aaa2b5eb94d158cdfacacee584605",
      "0ebe3079c71843eb837fb62c487e6ee5",
      "29caef64aee24ac39119804c7584a5f8",
      "5f3a58d44c5740b8af4e521a4f18cf3a",
      "f6241c4f7ee94e94aa0ec69699264909",
      "9254a9b4cf4c48ed96e0919c4a0f1125",
      "ec2d98fad36f4790a33e06ddba625cd3"
     ]
    },
    "id": "UmIIaTzcF78K",
    "outputId": "469ed115-bbcd-469f-d1dd-23d52eb03db7"
   },
   "outputs": [],
   "source": [
    "history=model_flex.fit(X_train, y_train,\n",
    "                      epochs=EPOCHS,\n",
    "                      verbose=0,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      callbacks=[TqdmCallback(verbose=1)]\n",
    "                    )\n",
    "plt.plot(history.history['loss'], label = 'Training Loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
    "plt.axhline(y=nll_naive, color='r', linestyle='--', label='Null Model NLL')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.ylim(0, 7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9PgbS7L2gghL",
    "outputId": "4fd21fd5-7b86-4bb5-b1e4-68cd581fc9c8"
   },
   "outputs": [],
   "source": [
    "#Sort the list and find the 5 highest values\n",
    "indices =  [0,1,2,3,5]\n",
    "ages = np.arange(-1,100,0.5)\n",
    "for i in indices:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(X_test[i])\n",
    "    d = output_to_gaussian_distribution(model_flex(X_test[i:i+1]))\n",
    "    mean_age = d.mean.cpu().detach().numpy()\n",
    "    plt.title(\"pred (mean): \"+ str(round(mean_age[0][0])) + \"   true : \"+ str(y_test[i]))\n",
    "    # Compute the Gaussian distribution output\n",
    "    # Ensure `ages` is converted properly and matches `d`'s device\n",
    "    ages_tensor = torch.tensor(ages, dtype=torch.float32, device=d.loc.device)\n",
    "    log_prob = d.log_prob(ages_tensor)\n",
    "    # Convert to probability (exp of log_prob) and move to CPU for further processing\n",
    "    ds = torch.exp(log_prob).detach().cpu().numpy()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(ages, ds[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deXn_qkfPtgW"
   },
   "source": [
    "#### Look at the predicted mean and the predicted sigma of the CPD on the testset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hny-EJzvjk0z"
   },
   "source": [
    "### Choose the one which are most sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n9VbrMM930X_",
    "outputId": "0e0ee4d2-7242-402c-fe82-277076b339cd"
   },
   "outputs": [],
   "source": [
    "batch_size = 100  # Adjust this value based on your memory capacity\n",
    "uncertainty_flex = []\n",
    "uncertainty_flex = model_flex.predict(X_test)\n",
    "uncertainty_flex = np.array(uncertainty_flex)\n",
    "#Sort the list and find the 5 highest values\n",
    "indices = np.argsort(uncertainty_flex[:,0])[:5]\n",
    "ages = np.arange(-1,8,0.1)\n",
    "for i in indices:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(X_test[i])\n",
    "    d = output_to_gaussian_distribution(model_flex(X_test[i:i+1]))\n",
    "    mean_age = d.mean.cpu().detach().numpy()\n",
    "    plt.title(\"pred (mean): \"+ str(round(mean_age[0][0],2)) + \"   true : \"+ str(y_test[i]))\n",
    "    # Compute the Gaussian distribution output\n",
    "    # Ensure `ages` is converted properly and matches `d`'s device\n",
    "    ages_tensor = torch.tensor(ages, dtype=torch.float32, device=d.loc.device)\n",
    "    log_prob = d.log_prob(ages_tensor)\n",
    "    # Convert to probability (exp of log_prob) and move to CPU for further processing\n",
    "    ds = torch.exp(log_prob).detach().cpu().numpy()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(ages, ds[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVhWyihDMLIV"
   },
   "source": [
    "### NLL and MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BvcFU72RMLIV",
    "outputId": "4e1286be-92dd-4dfb-9244-3799dfc8b352"
   },
   "outputs": [],
   "source": [
    "# Since the NLL is also the loss function, we can also use the evaluate function of keras. Which is much faster.\n",
    "nll_flex = model_flex.evaluate(X_test,y_test,verbose=0)\n",
    "print(\"NLL, MAE, and MSE for flexible sigma model: \", nll_flex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T5jKRABJdfN"
   },
   "source": [
    "Mean Absolute Error for the Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-erio6khTRW",
    "outputId": "6d545dc2-bc90-45f7-98ba-065839ecee18"
   },
   "outputs": [],
   "source": [
    "np.mean(np.abs((y_test - mu_naive)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4KqLgr4MLIY"
   },
   "source": [
    "# Suggestion for further exercises (optional)\n",
    "\n",
    "The gausian distribution is not the best distribution to model the age. For example the Log-Normal. This would give you a model that is not able to predict negative ages. And the result would look like."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3d_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
