{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJE2B4XUDNWu"
   },
   "source": [
    "# Age Regression with torch distributions\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorchiefs/dl_course_2025/blob/master/notebooks/15_faces_regression_keras_torch.ipynb)\n",
    "\n",
    "In this notebook you will learn how work with a Distribution in torch. You will set up regression models that are able to output a gaussian conditional probability distribution. You will define different models with Keras and optimize the negative log likelihood (NLL). You will model the conditional probability distribution as a Normal distribution with a constant and flexible standart deviation $\\sigma$. The mean $\\mu$ of the CPD will depend non-linearly on the input. You will compare the NLL of the two models with the constant and felxible standart deviation $\\sigma$. As input data you will use images of faces and you will try to predict the conditional probability distribution of their age.\n",
    "\n",
    "**Dataset:**\n",
    "You work with a the UTKFace dataset. It is a large dataset with a large age span (range from 0 to 116 years old). The dataset consists of over 20,000 face images with annotations of age, gender, and ethnicity. The data is already preprocessed and rescaled (80x80 pixels) so you can work with it. You will only use the information of the age and image.\n",
    "\n",
    "**Content:**\n",
    "* Load and and split the dataset\n",
    "* Fit a model with keras and torch distribution that models the CPD with a non-linear mean $\\mu$ and a constant standart deviation $\\sigma$ .\n",
    "* Fit a model with keras and torch distribution that models the CPD with a non-linear mean $\\mu$ and a flexible standart deviation $\\sigma$ with TFP.\n",
    "* Compare the two models based on the NLL loss on the test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fIXm9v3JSsK"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2041,
     "status": "ok",
     "timestamp": 1732721787001,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "8uxwN1Z8uZB3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten , Activation, Dropout, Input, Concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "from torch.distributions import Normal\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdnkSVWmJUXX"
   },
   "source": [
    "#### Loading the data, if it is not loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1732721787013,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "SxbUKL78JVKy"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('X_faces.npy'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/5m7nmebpjysqtus/X_faces.npy?dl=1\",\n",
    "    \"X_faces.npy\")\n",
    "\n",
    "if not os.path.isfile('Y_age.npy'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/flpyvgdqoatdw0g/Y_age.npy?dl=1\",\n",
    "    \"Y_age.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1732721787166,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "_B_EJ00sKIiN"
   },
   "outputs": [],
   "source": [
    "X=np.load(\"X_faces.npy\")\n",
    "Y=np.load(\"Y_age.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4PHsH3dJdT6"
   },
   "source": [
    "#### Splitting the data into train, val and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1732721787639,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "Mk4yqoyEZ80S"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=201)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1732721787654,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "-6m1YVhpZ-wu",
    "outputId": "696b2108-f39a-4aba-b267-55b484047b33"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOc3Er5yNCUH"
   },
   "source": [
    "#### Looking at the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2297,
     "status": "ok",
     "timestamp": 1732721789952,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "T5pSRxfiNBT_",
    "outputId": "d10932d8-fd38-47af-97b7-0b323c9f2ae9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i in range(0,25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(\"Age : \"+ str(y_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wET5EAj1KGUk"
   },
   "source": [
    "#### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1732721790635,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "4LtYwRKyaWUR"
   },
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_val=X_val/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1732721791146,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "I2_-fUp88Zxn"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,dtype=\"float32\")\n",
    "X_val = np.array(X_val,dtype=\"float32\")\n",
    "X_test = np.array(X_test,dtype=\"float32\")\n",
    "\n",
    "y_train = np.array(y_train,dtype=\"float32\")\n",
    "y_val = np.array(y_val,dtype=\"float32\")\n",
    "y_test = np.array(y_test,dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwwWDz3ILy2V"
   },
   "source": [
    "#### Looking at the distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1732721791350,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "SHJvwt2aKNeC",
    "outputId": "bbe482fa-6d4c-4e5f-cbbb-5c69140b9ba5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_train,bins=30)\n",
    "plt.title(\"Age dist train\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_val,bins=30)\n",
    "plt.title(\"Age dist val\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WP5PYd0Mu5K"
   },
   "source": [
    "## Fit a regression model with constant variance\n",
    "In the next cells you will define and fit a model on the face images. You will use a CNN to model the mu parameter of  a gaussian conditional probability distribution, the sigma will be constant for all inputs. For the loss we use the NLL. Note that we will use the trick with a second input that will be all ones, to model the constant sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1732721791351,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "5fiYRgoDOxfi"
   },
   "outputs": [],
   "source": [
    "kernel_size = (3, 3)\n",
    "pool_size = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 370232,
     "status": "ok",
     "timestamp": 1732722161584,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "SN7aTf9CUDEQ",
    "outputId": "95e3b2f4-cf8b-4a19-b073-2fc9ff2231e5"
   },
   "outputs": [],
   "source": [
    "def NLL(y_true, output):\n",
    "    mean = output[:, 0]\n",
    "    log_variance = output[:, 1]\n",
    "    scale = torch.exp(log_variance)  # Ensure positive variance\n",
    "    dist = Normal(loc=mean, scale=scale) # use distribution here\n",
    "    return -dist.log_prob(torch.tensor(y_true, dtype=torch.float32)).mean()\n",
    "\n",
    "\n",
    "input1 = Input(shape=(80,80,3))\n",
    "input2 = Input(shape=(1,))\n",
    "x = Convolution2D(16,kernel_size,padding='same',activation=\"relu\")(input1)\n",
    "x = Convolution2D(16,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(500,activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(50,activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out1 = Dense(1)(x)       #mu\n",
    "out2 = Dense(1)(input2)  #sigma , ## use a trick with two inputs, input2 is just ones\n",
    "params = Concatenate()([out1,out2])\n",
    "model_const_sd = Model(inputs=[input1,input2], outputs=params)\n",
    "model_const_sd.compile(keras.optimizers.Adam(), loss=NLL)\n",
    "\n",
    "\n",
    "# train the model\n",
    "\n",
    "history=model_const_sd.fit([X_train, np.expand_dims(np.ones(len(X_train)),1)], y_train,\n",
    "                    batch_size=16,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=([X_val,np.expand_dims(np.ones(len(X_val)),1)], y_val)\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "ok",
     "timestamp": 1732722161742,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "EW5SvN-0wqdz",
    "outputId": "89af708f-eabe-46d7-84bc-431b21e337ca"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdN8Zqd_OR1G"
   },
   "source": [
    "#### Look at the predicted mean of the CPD on the testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "14RK1M0hXUj8awk6KCqERwqfuP5pW8p8g"
    },
    "executionInfo": {
     "elapsed": 2969,
     "status": "ok",
     "timestamp": 1732722164712,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "_B2MyFignucQ",
    "outputId": "b30240b7-7df8-420a-dbed-3a33bf22d9c7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "for i in range(0,25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "    pred=model_const_sd([X_test[i:i+1], np.expand_dims(np.ones(len(X_test[i:i+1])),1)]).data.detach().cpu().numpy()[0][0]\n",
    "    plt.title(\"pred : \"+ str(round(float(pred), 2)) + \"   true : \"+ str(y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DYfIyPcOfCi"
   },
   "source": [
    "#### Look at the predicted mean and the predicted sigma of the CPD on the testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1732722164725,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "_OUEi8MB7fxr"
   },
   "outputs": [],
   "source": [
    "# distribution used for the model -> model outputs loaction and a value for the scalinpout\n",
    "def my_dist(output):\n",
    "    mean = output[:, 0]\n",
    "    log_variance = output[:, 1]\n",
    "    scale = torch.exp(log_variance)  # Ensure positive scale\n",
    "    return Normal(loc=mean, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1826,
     "status": "ok",
     "timestamp": 1732722166551,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "KYnfRtAMjZg3",
    "outputId": "0a5f59f2-5e6a-4757-dc8f-f2a219d54374"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(X_test[i])\n",
    "\n",
    "    # predictions\n",
    "    pred = model_const_sd([X_test[i:i+1], np.expand_dims(np.ones(len(X_test[i:i+1])), 1)])\n",
    "    pred = pred.data.detach().cpu().numpy()\n",
    "\n",
    "    # distribution\n",
    "    dist = my_dist(torch.Tensor(pred))\n",
    "\n",
    "\n",
    "    plt.title(\"Pred: \" + str(round(float(dist.mean), 2)) +\n",
    "              \"   True: \" + str(y_test[i]))\n",
    "    # plot cdf\n",
    "    plt.subplot(1, 2, 2)\n",
    "    x_range = np.arange(-10, 100, 0.2)\n",
    "    log_probs = dist.log_prob(torch.tensor(x_range, dtype=torch.float32))  # Remove [0]\n",
    "    plt.plot(x_range, torch.exp(log_probs).detach().cpu().numpy())  # Convert log-probs to PDF\n",
    "    plt.title(\"Probability Distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzkJVe4oOkIh"
   },
   "source": [
    "## Fit a regression model with felxible variance\n",
    "In the next cells you will afain define and fit a model on the face images. You will use a CNN to model the mu parameter of a gaussian conditional probability distribution, but this time the sigma will not be constant for all inputs. Every iamge will be able to have a different sigma. For the loss we use the NLL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1732722166553,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "_8vYpToHZ-7i"
   },
   "outputs": [],
   "source": [
    "def NLL(y_true, output):\n",
    "    mean = output[:, 0]\n",
    "    log_variance = output[:, 1]\n",
    "    scale = torch.exp(log_variance)  # Ensure positive variance\n",
    "    dist = Normal(loc=mean, scale=scale) # use distribution here\n",
    "    return -dist.log_prob(torch.tensor(y_true, dtype=torch.float32)).mean()\n",
    "\n",
    "inputs = Input(shape=(80,80,3))\n",
    "x = Convolution2D(16,kernel_size,padding='same',activation=\"relu\")(inputs)\n",
    "x = Convolution2D(16,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = Convolution2D(32,kernel_size,padding='same',activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(500,activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(50,activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(2)(x)\n",
    "\n",
    "\n",
    "model_flex = Model(inputs=inputs, outputs=x)\n",
    "model_flex.compile(keras.optimizers.Adam(), loss=NLL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309078,
     "status": "ok",
     "timestamp": 1732722475632,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "_Ddl6NgxZ-0q",
    "outputId": "8bbd2e40-5c19-4c64-8171-1c1b6914eba3"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "history=model_flex.fit(X_train, np.array(y_train,dtype=\"float32\"),\n",
    "                  batch_size=16,\n",
    "                  epochs=40,\n",
    "                  verbose=1,\n",
    "                  validation_data=(X_val, np.array(y_val,dtype=\"float32\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1732722475728,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "DItfSKvh1Whm",
    "outputId": "ed205b39-c9d9-443a-a9cd-d42e902ca98e"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKdLA-HgPmmL"
   },
   "source": [
    "#### Look at the predicted mean of the CPD on the testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1RiAkWsD8CjDaaI4Wu--wZ_LLDYA86uYb"
    },
    "executionInfo": {
     "elapsed": 2931,
     "status": "ok",
     "timestamp": 1732722478660,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "S0e8El8k1rLb",
    "outputId": "f82fbfab-caea-49fb-bcdb-02db6b95bb33"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "for i in range(0,25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "    pred=model_flex(X_test[i:i+1]).data.detach().cpu().numpy()[0][0]\n",
    "    plt.title(\"pred : \"+ str(round(float(pred), 2)) + \"   true : \"+ str(y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deXn_qkfPtgW"
   },
   "source": [
    "#### Look at the predicted mean and the predicted sigma of the CPD on the testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1576,
     "status": "ok",
     "timestamp": 1732722480248,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "Ci17D_-o3JUs",
    "outputId": "65e3c085-a8e3-4a9e-8675-41b44f1a2395"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(X_test[i])\n",
    "\n",
    "    # predictions\n",
    "    pred = model_flex(X_test[i:i+1])\n",
    "    pred = pred.data.detach().cpu().numpy()\n",
    "\n",
    "    # distribution\n",
    "    dist = my_dist(torch.Tensor(pred))\n",
    "\n",
    "\n",
    "    plt.title(\"Pred: \" + str(round(float(dist.mean), 2)) +\n",
    "              \"   True: \" + str(y_test[i]))\n",
    "    # plot cdf\n",
    "    plt.subplot(1, 2, 2)\n",
    "    x_range = np.arange(-10, 100, 0.2)\n",
    "    log_probs = dist.log_prob(torch.tensor(x_range, dtype=torch.float32))  # Remove [0]\n",
    "    plt.plot(x_range, torch.exp(log_probs).detach().cpu().numpy())  # Convert log-probs to PDF\n",
    "    plt.title(\"Probability Distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hvkp3IjxPz_8"
   },
   "source": [
    "### ðŸ”§ **YOUR TASK:**\n",
    "Calculate the MSE the RMSE and the NLL for both models on the testset.  \n",
    "Which model would you prefer in practice and why?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1732722480251,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "QRJnuS9x1cq8"
   },
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELn8R9rtLaBn"
   },
   "source": [
    "<details>\n",
    "  <summary>ðŸ’¡ Hint:</summary>\n",
    "\n",
    "\n",
    "heres how you geet all the predicitons without OOM\n",
    "\n",
    "```\n",
    "i = 0\n",
    "mu1 = []\n",
    "mu2 = []\n",
    "for i in range(len(X_test)):\n",
    "    mu1.append( model_const_sd([X_test[i:i+1], np.expand_dims(np.ones(len(X_test[i:i+1])), 1)]).data.detach().cpu().numpy()[0])\n",
    "    mu2.append( model_flex([X_test[i:i+1]]).data.detach().cpu().numpy()[0])\n",
    "\n",
    "mu1=np.array(mu1)\n",
    "mu2=np.array(mu2)\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NflfKGV7AGpG"
   },
   "source": [
    "### `ðŸ”‘` **Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTcZp9OjMjVu"
   },
   "source": [
    "<details>\n",
    "  <summary>ðŸ”‘ Click here to View Answers:</summary>\n",
    "\n",
    "The model with the nonflexible CPD has the lower MSE and RMSE but NLL is still larger.\n",
    "\n",
    "The flexible model outputs a distribution for every input and therefore is more useful in practice.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "executionInfo": {
     "elapsed": 50685,
     "status": "ok",
     "timestamp": 1732722530936,
     "user": {
      "displayName": "Pascal BÃ¼hler",
      "userId": "01261418420162852179"
     },
     "user_tz": -60
    },
    "id": "0PNR_vCFtjvq",
    "outputId": "5e220d61-f569-45ca-b51a-7765318f56c8"
   },
   "outputs": [],
   "source": [
    "# @title ðŸ”‘ Solution Code { display-mode: \"form\" }\n",
    "# prediction in for loop because else OOM error (Out Of Memory)\n",
    "i = 0\n",
    "mu1 = []\n",
    "mu2 = []\n",
    "for i in range(len(X_test)):\n",
    "    mu1.append( model_const_sd([X_test[i:i+1], np.expand_dims(np.ones(len(X_test[i:i+1])), 1)]).data.detach().cpu().numpy()[0])\n",
    "    mu2.append( model_flex([X_test[i:i+1]]).data.detach().cpu().numpy()[0])\n",
    "\n",
    "mu1=np.array(mu1)\n",
    "mu2=np.array(mu2)\n",
    "\n",
    "# metrics\n",
    "mse_1 = np.average(np.square(mu1[:,0]-y_test))\n",
    "rmse_1 = np.sqrt(mse_1)\n",
    "nll_1 = model_const_sd.evaluate([X_test,np.expand_dims(np.ones(len(X_test)),1)],y_test,verbose=0)\n",
    "\n",
    "mse_2 = np.average(np.square(mu2[:,0]-y_test))\n",
    "rmse_2 = np.sqrt(mse_2)\n",
    "nll_2 = model_flex.evaluate(X_test,y_test,verbose=0)\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "         { 'MSE' : mse_1, 'RMSE' : rmse_1, 'nll ' : nll_1}, index=['model const sigma'])\n",
    "df2 = pd.DataFrame(\n",
    "         { 'MSE' : mse_2, 'RMSE' : rmse_2, 'nll ' : nll_2}, index=['model flex sigma'])\n",
    "pd.concat([df1,df2])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "NflfKGV7AGpG"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dlcourse3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
