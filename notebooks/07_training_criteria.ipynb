{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping Criteria\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorchiefs/dl_course_2025/blob/master/notebooks/07_training_criteria.ipynb)\n",
    "\n",
    "**Task:**\n",
    "In this Notebook you will see how early stopping is implemented to prevent overfitting and avoid uneccessary computational cost.\n",
    "\n",
    "\n",
    "**Dataset:** We simulate some data\n",
    "\n",
    "**Content:**\n",
    "* load the original MNIST data and create a randomly pixel shuffled version of the data\n",
    "* visualize samples of the orginal and shuffled version of the data\n",
    "* use keras to train a CNN with the original and shuffled data and compare the perfomance on new unseen test data\n",
    "* check if the local structure of the pixels within the images have an impact on the classification performance when you use a CNN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5250,
     "status": "ok",
     "timestamp": 1747150997258,
     "user": {
      "displayName": "Pascal Bühler",
      "userId": "01261418420162852179"
     },
     "user_tz": -120
    },
    "id": "Yi9WP6IXTm_2",
    "outputId": "246250b7-3f8d-4ae0-8a60-7919e24b0d97"
   },
   "outputs": [],
   "source": [
    "# load required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "print(f'Keras_version: {keras.__version__}')# 3.5.0\n",
    "print(f'torch_version: {torch.__version__}')# 2.5.1+cu121\n",
    "print(f'keras backend: {keras.backend.backend()}')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lets create some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747151004834,
     "user": {
      "displayName": "Pascal Bühler",
      "userId": "01261418420162852179"
     },
     "user_tz": -120
    },
    "id": "nln3Ic67TrS8"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=2000, n_features=20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame(X_train, columns=[f\"Feature_{i}\" for i in range(X.shape[1])])\n",
    "df_train['Target'] = y_train\n",
    "\n",
    "df_val = pd.DataFrame(X_val, columns=[f\"Feature_{i}\" for i in range(X.shape[1])])\n",
    "df_val['Target'] = y_val\n",
    "\n",
    "# Plotting a pair plot of the first two features and target for training data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df_train['Feature_0'], df_train['Feature_1'], c=df_train['Target'], cmap='viridis', alpha=0.7)\n",
    "plt.title(\"Scatter Plot of Feature_0 vs Feature_1 (Training Data)\")\n",
    "plt.xlabel(\"Feature_0\")\n",
    "plt.ylabel(\"Feature_1\")\n",
    "plt.colorbar(label=\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747151116876,
     "user": {
      "displayName": "Pascal Bühler",
      "userId": "01261418420162852179"
     },
     "user_tz": -120
    },
    "id": "2eD6EpbNTtkM"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747151118953,
     "user": {
      "displayName": "Pascal Bühler",
      "userId": "01261418420162852179"
     },
     "user_tz": -120
    },
    "id": "DK5s40_eT8NM"
   },
   "outputs": [],
   "source": [
    "# Setting Up Early Stopping Callback\n",
    "# Early Stopping is a technique to prevent overfitting by monitoring validation loss\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6757,
     "status": "ok",
     "timestamp": 1747151127104,
     "user": {
      "displayName": "Pascal Bühler",
      "userId": "01261418420162852179"
     },
     "user_tz": -120
    },
    "id": "mxdjLmRGTiKL",
    "outputId": "a14cc300-d36d-4262-82a2-dc74bad04a71"
   },
   "outputs": [],
   "source": [
    "# Training the Model with Early Stopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1747151131612,
     "user": {
      "displayName": "Pascal Bühler",
      "userId": "01261418420162852179"
     },
     "user_tz": -120
    },
    "id": "2J2RFRHrUhpk",
    "outputId": "609df4cb-4452-432c-bbf5-a34b45901e2b"
   },
   "outputs": [],
   "source": [
    "# Plotting Training History\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.axvline(len(history.history['val_loss']) - 5, color='r', linestyle='--', label='Early Stopping Trigger')\n",
    "plt.title('Training and Validation Loss with Early Stopping')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This notebook demonstrates the importance of early stopping as a stopping criterion in training.\n",
    "It helps prevent overfitting by monitoring validation loss and stopping training when it no longer improves."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNgHOTXZe86fvTGv47kQJl1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
